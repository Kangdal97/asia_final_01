{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kogpt3_train_on_colab.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!nvidia-smi\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!ls drive/'My Drive'/'Colab Notebooks'/\n",
        "!pip install -r drive/'My Drive'/'Colab Notebooks'/test_project/requirements.txt\n",
        "import sys\n",
        "sys.path.append('drive/My Drive/Colab Notebooks/')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K_aw2M9o-9Hx",
        "outputId": "4cf766b5-aab4-488b-db75-f29b159bcfff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Tue Jan 25 07:34:16 2022       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 495.46       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   36C    P0    26W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n",
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "dialogLM  exam\tfinal_project  test_project\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.7/dist-packages (from -r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 1)) (1.1.5)\n",
            "Requirement already satisfied: pytorch_lightning==1.2.10 in /usr/local/lib/python3.7/dist-packages (from -r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.2.10)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from -r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 3)) (1.10.0+cu111)\n",
            "Requirement already satisfied: transformers==4.5.1 in /usr/local/lib/python3.7/dist-packages (from -r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (4.5.1)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (21.3)\n",
            "Requirement already satisfied: tqdm>=4.41.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (4.62.3)\n",
            "Requirement already satisfied: PyYAML!=5.4.*,>=5.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (6.0)\n",
            "Requirement already satisfied: numpy>=1.16.6 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.19.5)\n",
            "Requirement already satisfied: tensorboard!=2.5.0,>=2.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (2.7.0)\n",
            "Requirement already satisfied: future>=0.17.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.18.2)\n",
            "Requirement already satisfied: fsspec[http]>=0.8.1 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (2022.1.0)\n",
            "Requirement already satisfied: torchmetrics==0.2.0 in /usr/local/lib/python3.7/dist-packages (from pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.2.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (2019.12.20)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (4.10.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (3.4.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (2.23.0)\n",
            "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (0.10.3)\n",
            "Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/dist-packages (from transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (0.0.47)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 3)) (3.10.0.2)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (3.8.1)\n",
            "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.4.6)\n",
            "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.8.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (57.4.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.0.1)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.37.1)\n",
            "Requirement already satisfied: grpcio>=1.24.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.43.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (3.3.6)\n",
            "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.6.1)\n",
            "Requirement already satisfied: protobuf>=3.6.0 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (3.17.3)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.35.0)\n",
            "Requirement already satisfied: absl-py>=0.4 in /usr/local/lib/python3.7/dist-packages (from tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.12.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from absl-py>=0.4->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.15.0)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (4.2.4)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (4.8)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.2.8)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (3.7.0)\n",
            "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.7/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.4.8)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (2.10)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (1.24.3)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard!=2.5.0,>=2.2.0->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (3.1.1)\n",
            "Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.7/dist-packages (from pandas->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 1)) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 1)) (2.8.2)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (2.0.10)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.3.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (21.4.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (6.0.2)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.2.0)\n",
            "Requirement already satisfied: asynctest==0.13.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (0.13.0)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->fsspec[http]>=0.8.1->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (1.7.2)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->pytorch_lightning==1.2.10->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 2)) (3.0.6)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers==4.5.1->-r drive/My Drive/Colab Notebooks/test_project/requirements.txt (line 4)) (1.1.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.environ['CUDA_LAUNCH_BLOCKING'] = \"1\"\n",
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, Dataset\n",
        "from transformers import PreTrainedTokenizerFast, GPT2LMHeadModel"
      ],
      "metadata": {
        "id": "1ylpzlYrCxYn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = GPT2LMHeadModel.from_pretrained('skt/kogpt2-base-v2')\n",
        "tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "    \"skt/kogpt2-base-v2\", bos_token='<s>', eos_token='</s>', unk_token='<unk>', pad_token='<pad>', mask_token='<unused0>')\n",
        "\n",
        "root_path='drive/My Drive/Colab Notebooks/test_project'\n",
        "data_path = f\"{root_path}/Chatbot_data/ChatbotData.csv\"\n",
        "\n",
        "Chatbot_Data = pd.read_csv(data_path)\n",
        "# Test 용으로 300개 데이터만 처리한다.\n",
        "Chatbot_Data = Chatbot_Data[:300]\n",
        "Chatbot_Data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "McIDiwrL-3mM",
        "outputId": "a94f7a69-a31a-44c3-d7e9-7e805f78b2d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-8b585e01-14ce-4fc6-a282-78c99975dbf9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Q</th>\n",
              "      <th>A</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>12시 땡!</td>\n",
              "      <td>하루가 또 가네요.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1지망 학교 떨어졌어</td>\n",
              "      <td>위로해 드립니다.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>3박4일 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3박4일 정도 놀러가고 싶다</td>\n",
              "      <td>여행은 언제나 좋죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>PPL 심하네</td>\n",
              "      <td>눈살이 찌푸려지죠.</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8b585e01-14ce-4fc6-a282-78c99975dbf9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8b585e01-14ce-4fc6-a282-78c99975dbf9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8b585e01-14ce-4fc6-a282-78c99975dbf9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "                 Q            A  label\n",
              "0           12시 땡!   하루가 또 가네요.      0\n",
              "1      1지망 학교 떨어졌어    위로해 드립니다.      0\n",
              "2     3박4일 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "3  3박4일 정도 놀러가고 싶다  여행은 언제나 좋죠.      0\n",
              "4          PPL 심하네   눈살이 찌푸려지죠.      0"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class ChatbotDataset(Dataset):\n",
        "    def __init__(self, chats, max_len=40):  # 데이터셋의 전처리를 해주는 부분\n",
        "        self._data = chats\n",
        "        self.max_len = max_len\n",
        "        self.q_token = '<usr>'\n",
        "        self.a_token = '<sys>'\n",
        "        self.sent_token = '<unused1>'\n",
        "        self.eos = '</s>'\n",
        "        self.mask = '<unused0>'\n",
        "        self.tokenizer = PreTrainedTokenizerFast.from_pretrained(\n",
        "            \"skt/kogpt2-base-v2\", bos_token='<s>', eos_token='</s>',\n",
        "            unk_token='<unk>', pad_token='<pad>', mask_token='<unused0>')\n",
        "\n",
        "    def __len__(self):  # chatbotdata 의 길이를 리턴한다.\n",
        "        return len(self._data)\n",
        "\n",
        "    def __getitem__(self, idx):  # 로드한 챗봇 데이터를 차례차례 DataLoader로 넘겨주는 메서드\n",
        "        turn = self._data.iloc[idx]\n",
        "        q = turn['Q']\n",
        "        a = turn['A']\n",
        "        sentiment = str(turn['label'])\n",
        "        q_toked = self.tokenizer.tokenize(self.q_token + q + \\\n",
        "                                          self.sent_token + sentiment)\n",
        "        q_len = len(q_toked)\n",
        "        a_toked = self.tokenizer.tokenize(self.a_token + a + self.eos)\n",
        "        a_len = len(a_toked)\n",
        "        if q_len + a_len > self.max_len:\n",
        "            a_len = self.max_len - q_len\n",
        "            if a_len <= 0:\n",
        "                q_toked = q_toked[-(int(self.max_len / 2)):]\n",
        "                q_len = len(q_toked)\n",
        "                a_len = self.max_len - q_len\n",
        "                assert a_len > 0\n",
        "            a_toked = a_toked[:a_len]\n",
        "            a_len = len(a_toked)\n",
        "            assert a_len == len(a_toked), f'{a_len} ==? {len(a_toked)}'\n",
        "        # [mask, mask, ...., mask, ..., <bos>,..A.. <eos>, <pad>....]\n",
        "        labels = [\n",
        "                     self.mask,\n",
        "                 ] * q_len + a_toked[1:]\n",
        "\n",
        "        # mask = 질문길이 0 + 답변길이 1 + 나머지 0\n",
        "        mask = [0] * q_len + [1] * a_len + [0] * (self.max_len - q_len - a_len)\n",
        "        self.max_len\n",
        "        labels_ids = self.tokenizer.convert_tokens_to_ids(labels)\n",
        "        while len(labels_ids) < self.max_len:\n",
        "            labels_ids += [self.tokenizer.pad_token_id]\n",
        "        token_ids = self.tokenizer.convert_tokens_to_ids(q_toked + a_toked)\n",
        "        while len(token_ids) < self.max_len:\n",
        "            token_ids += [self.tokenizer.pad_token_id]\n",
        "        return (token_ids, np.array(mask),\n",
        "                labels_ids)"
      ],
      "metadata": {
        "id": "0maY7oXY-36z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def collate_batch(batch):\n",
        "    data = [item[0] for item in batch]\n",
        "    mask = [item[1] for item in batch]\n",
        "    label = [item[2] for item in batch]\n",
        "    return torch.LongTensor(data), torch.LongTensor(mask), torch.LongTensor(label)\n",
        "\n",
        "train_set = ChatbotDataset(Chatbot_Data, max_len=40)\n",
        "train_dataloader = DataLoader(train_set, batch_size=32, num_workers=0, shuffle=True, collate_fn=collate_batch,)"
      ],
      "metadata": {
        "id": "NUJ3u3Zq-7jN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ctx = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "device = torch.device(ctx)\n",
        "model.to(device)\n",
        "model.train()\n",
        "\n",
        "learning_rate = 3e-5\n",
        "criterion = torch.nn.CrossEntropyLoss(reduction=\"none\")\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
        "\n",
        "epoch = 1\n",
        "Sneg = -1e18\n",
        "\n",
        "ctx = 'cuda' if torch.cuda.is_available() else 'cpu'"
      ],
      "metadata": {
        "id": "Dz8vivYf_Ua8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "save_ckpt_path = '/content/drive/MyDrive/Colab Notebooks/test_project/checkpoint/test.pth'\n",
        "save_step = 100\n",
        "\n",
        "\n",
        "pre_epoch, pre_loss, train_step = 0, 0, 0\n",
        "########################################### 학습 모델 로딩  ##################\n",
        "if os.path.isfile(save_ckpt_path):\n",
        "    checkpoint = torch.load(save_ckpt_path, map_location=device)\n",
        "    pre_epoch = checkpoint['epoch']\n",
        "    pre_loss = checkpoint['loss']\n",
        "    train_step =  checkpoint['train_no']\n",
        "    total_train_step =  checkpoint['total_train_step']\n",
        "\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "    print(f\"load pretrain from: {save_ckpt_path}, epoch={pre_epoch}\")  #, loss={pre_loss}\\n\")\n",
        "    # best_epoch += 1\n",
        "########################################################################################\n",
        "count = 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N5ghubqIP-f_",
        "outputId": "b904f2c8-4af4-4694-b22f-f5af80a6fb11"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "load pretrain from: /content/drive/MyDrive/Colab Notebooks/test_project/checkpoint/test.pth, epoch=0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print (\"start\")\n",
        "for epoch in range(epoch):\n",
        "    for batch_idx, samples in enumerate(train_dataloader):\n",
        "        optimizer.zero_grad()\n",
        "        token_ids, mask, label = samples\n",
        "        if ctx == 'cuda':\n",
        "            token_ids, mask, label = token_ids.to(ctx), mask.to(ctx), label.to(ctx)\n",
        "        out = model(token_ids)\n",
        "        out = out.logits      #Returns a new tensor with the logit of the elements of input\n",
        "        mask_3d = mask.unsqueeze(dim=2).repeat_interleave(repeats=out.shape[2], dim=2)\n",
        "        mask_out = torch.where(mask_3d == 1, out, Sneg * torch.ones_like(out))\n",
        "        loss = criterion(mask_out.transpose(2, 1), label)\n",
        "        # 평균 loss 만들기 avg_loss[0] / avg_loss[1] <- loss 정규화\n",
        "        avg_loss = loss.sum() / mask.sum()\n",
        "        avg_loss.backward()\n",
        "        # 학습 끝\n",
        "        optimizer.step()\n",
        "\n",
        "        if (count > 0 and count % save_step == 0):\n",
        "\n",
        "            torch.save({\n",
        "                'epoch': epoch,\n",
        "                'train_no': count,\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'total_train_step': len(train_dataloader),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': loss\n",
        "            }, save_ckpt_path)\n",
        "        count += 1\n",
        "\n",
        "torch.save({\n",
        "    'epoch': epoch,\n",
        "    'train_no': count,\n",
        "    'model_state_dict': model.state_dict(),\n",
        "    'total_train_step': len(train_dataloader),\n",
        "    'optimizer_state_dict': optimizer.state_dict(),\n",
        "    'loss': loss\n",
        "    }, save_ckpt_path)\n",
        "print (\"end\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfByTrDx_bR5",
        "outputId": "f4b9d9bb-0468-49e3-b6a6-43e82a6f1926"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start\n",
            "end\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# sent = '0'\n",
        "# with torch.no_grad():\n",
        "#     while 1:\n",
        "#         q = input(\"user > \").strip()\n",
        "#         if q == \"quit\":\n",
        "#             break\n",
        "#         a = \"\"\n",
        "#         while 1:\n",
        "#             input_ids = torch.LongTensor(tokenizer.encode(\"<usr>\" + q + '<unused1>' + sent + \"<sys>\" + a)).unsqueeze(dim=0)\n",
        "#             if ctx == 'cuda':\n",
        "#                 input_ids = input_ids.to(ctx)\n",
        "#             pred = model(input_ids)\n",
        "#             pred = pred.logits\n",
        "#             if ctx == 'cuda':\n",
        "#                 pred = pred.to(ctx)\n",
        "#             gen = tokenizer.convert_ids_to_tokens(torch.argmax(pred, dim=-1).squeeze().cpu().numpy().tolist())[-1]\n",
        "#             if gen == '</s>':\n",
        "#                 break\n",
        "#             a += gen.replace(\"▁\", \" \")\n",
        "#         print(\"Chatbot > {}\".format(a.strip()))"
      ],
      "metadata": {
        "id": "VhaLc1E6_cmY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ra4x5L1_AIjx"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}